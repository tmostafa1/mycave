#nltk_chapter3#exercise1
s= 'colorless'
print(s[:4]+'u'+s[4:])

#nltk_chapter3#exercise2
#dish-es, run-ning, nation-ality, un-do, pre-heat
s1='dishes'
print(s1[:4])
s2='running'
print(s2[:3])
s3='nationality'
print(s3[:6])

#nltk_chapter3#exercise8
def my_url(url1):
    from urllib import request #import request
    raw=request.urlopen(url1) #request to open the url and asign it to a variable
    raw1=raw.read().decode('utf8') #read the url and decode it
    from bs4 import BeautifulSoup #import beautifulsoup to parse the html markers
    raw2=BeautifulSoup(raw1).get_text() #parse html markers and get text
    
    print(raw2)

url1='http://www.nltk.org/'
my_url(url1)

#nltk_chapter3#exercise10
sent=['i', 'hate', 'that', 'guy']
new_sent=[(w, len(w)) for w in sent]
print(new_sent)

#nltk book chapter3#exercise11
 raw='i love you'
 raw1=raw.split('o')
 raw1
 
#nltk book chapter3#exercise12
 
 def prac(word):
     for i in word:
         print (i, '\n')

#nltk book chapter3#exercise14
words=['i', 'love', 'you', 'i', 'me']
words.sort()
words

words1=sorted(words)
words1

#nltk book chapter3#exercise18
tex1=open('F:\OneDriveGSU\OneDrive - Georgia State University\Python_practice\Julian.txt', 'r')
def pro_tex(tex1):
    tex2=tex1.read()#read the open text
    tex2=tex2.strip().lower().split()#turn the text into a list
    tex3=[] #create a new list
    for w in tex2: #for w in tex2
        if w.startswith('wh'): #set the if condition 
            tex3.append(w) #append words to the new list
    print(tex3) #print the list
tex1=open('F:\OneDriveGSU\OneDrive - Georgia State University\Python_practice\Julian.txt', 'r')
pro_tex(tex1)        

#nltk book chapter 3 exercise 19
tex1=open('F:\\OneDriveGSU\\OneDrive - Georgia State University\\Python_practice\\trial.txt', 'r')
tex2=tex1.readlines() #read the open text in line
tex3=[line.split() for line in tex2] #create a new text by splitting each line and making it a list
tex4=[[str(item[0]), int(item[-1])] for item in tex3]#specify that for each item in the list, the fist element will be a string and the second element, an integer
print(tex4)#print the new text



##nltk book chapter 3 #exercise 21_matched the solution but didn't run
def unknown(url):
    import nltk
    from urllib import request
    
    import re
    raw=request.urlopen(url) #open the url
    raw1=raw.read().decode('utf8') #read and decode it
    
    my_soup_raw=re.findall(r'[\s\(\[\{]([a-z]+)', raw1)#using regex, extract all substrings of lower case letters 
    my_soup= list(my_soup_raw) #make a list of the extracted text and assign that to a variable
    ref_lis=nltk.corpus.words.words() #open the word corpus url
    print(item for item in my_soup if item not in ref_lis)
    
#nltk book#chapter 3#number 31
saying=['After', 'all', 'is', 'said', 'and', 'done', ',', 'more', 'is', 'said', 'than', 'done', '.']     
lengths=[]
for item in saying:
    lengths.append(len(item))
print(lengths)

#nltk book#chapter 3#number 32
silly='newly formed bland ideas are inexpressible in an infuriating way' 
#32_a
bland=silly.split()
bland
#32_b
bland1=[]#create an empty list
for i in bland: #for every item in the first list
    bland1.append(i[1]) #append the second character of the item to the new list
stri1=''.join(bland1) #join the new list to a string
print(stri1) #print the string

#32_c
back_to=' '.join(bland)  
back_to    

#32_d
sor=sorted(bland)
print(*sor, sep='\n')

#nltk book#chapter 3#number 33
#a
'inexpressible'.index('re')
#returns the index of the first element
#b
words=['i', 'love', 'you']
words.index('love')
#c
silly='newly formed bland ideas are inexpressible in an infuriating way' 
bland=silly.split() #make the string into a list
bland.index('in')  #find our the index of the the word 'in'
phrase=bland[:6] #use list slicing to create a new list upto 'in'
final=' '.join(phrase) #convert the list to a string
final
#an alternative of the above
bland[:bland.index('in')]

#nltk book#chapter 3#number 27
from random import choice
def expression():
    raph=' '.join(random.choice('aehh') for x in range(200))
    raph1=raph.split()
    fin=' '.join(raph1)
    return fin
expression()

#nltk book#chapter 3#number 34
def convertNationality(word):
    if word.endswith('ian'): #if the input word ends with 'ian'
        return word[:-3]+'a'
print convertNationality('Canadinan')

##nltk book#chapter 3#number 29_revised
def ari(category):  
    word=nltk.corpus.brown.words() (categories=category)
    uw=sum(len(w)for w in word)\len(word)
    return 4.71*uw+0.5*us-21.43
print ari('lore)

###nltk book#chapter3#number_41
#list comprehension
import re
words = ['attribution', 'confabulation', 'elocution',
        'sequoia', 'tenacious', 'unidirectional']
vsequences=set([''.join(re.findall(r'[aeiou]', word)) for word in words])
sorted(vsequences)



   
